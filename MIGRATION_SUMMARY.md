# Migration Summary: Google Gemini ‚Üí Ollama (DeepSeek & Gemma)

**Date:** February 1, 2026  
**Status:** ‚úÖ Complete

---

## üéØ Overview

Successfully migrated YalOffice from Google Gemini AI to a hybrid architecture using local Ollama models (DeepSeek-R1 7B and Gemma 2 9B) for LLM tasks, and Deepgram for Speech-to-Text.

---

## üìù Files Created

### 1. Backend Services
- ‚úÖ `backend/src/services/ollamaService.ts` - New Ollama client wrapper
  - Connects to ollama-deepseek (port 11434)
  - Connects to ollama-gemma (port 11434)
  - Provides `generateWithDeepSeek()`, `generateWithGemma()`, `chatWithDeepSeek()`, `chatWithGemma()`
  - Includes interview-specific methods: `generateInterviewResponse()`, `analyzeInterview()`

### 2. Documentation
- ‚úÖ `AI_ARCHITECTURE.md` - Comprehensive AI architecture documentation
- ‚úÖ `MIGRATION_SUMMARY.md` - This file

### 3. Setup Scripts
- ‚úÖ `setup-ollama-models.sh` - Bash script for Linux/Mac
- ‚úÖ `setup-ollama-models.ps1` - PowerShell script for Windows

---

## üîÑ Files Modified

### Backend
1. **`backend/src/services/aiService.ts`** - Complete rewrite
   - ‚ùå Removed: Google Gemini SDK (`@google/generative-ai`)
   - ‚úÖ Added: Ollama integration via `ollamaService`
   - Updated all methods to use DeepSeek (parsing/screening) or Gemma (conversations)
   - Removed video analysis (not supported by Ollama)
   - Added note about PDF/Image requiring OCR preprocessing

### Agent (Python)
2. **`agent/main.py`** - Major updates
   - ‚ùå Removed: Google Gemini imports (`livekit.plugins.google`)
   - ‚ùå Removed: OpenAI imports (`livekit.plugins.openai`)
   - ‚úÖ Added: Cartesia TTS (`livekit.plugins.cartesia`)
   - ‚úÖ Added: Custom `OllamaLLM` class for Gemma 2 integration
   - ‚úÖ Changed: Interview prompts from Thai to English
   - ‚úÖ Changed: STT from Google/Deepgram Thai to Deepgram English (`en-US`)
   - ‚úÖ Changed:  TTS from Google Thai to Cartesia English

3. **`agent/requirements.txt`** - Updated dependencies
   - ‚ùå Removed: `livekit-plugins-google`
   - ‚ùå Removed: `livekit-plugins-openai`
   - ‚úÖ Added: `livekit-plugins-cartesia>=0.1.0`

---

## üèóÔ∏è Architecture Changes

### Before (Google Gemini)
```
Frontend ‚Üí Backend ‚Üí Google Gemini API (all AI tasks)
                  ‚Üì
              Google STT/TTS (Thai)
```

### After (Ollama + Deepgram)
```
Frontend ‚Üí Backend ‚Üí Ollama DeepSeek (resume parsing, screening)
                  ‚Üì
                  ‚Üí Ollama Gemma (interviews, conversations)
                  ‚Üì
                  ‚Üí Deepgram STT (English speech-to-text)
                  ‚Üì
                  ‚Üí Cartesia TTS (English text-to-speech)
```

---

## üîë AI Model Assignment

| Task | Model | Reasoning |
|------|-------|-----------|
| Resume Parsing | DeepSeek-R1 7B | Structured extraction, low hallucination |
| Resume Screening | DeepSeek-R1 7B | Deterministic scoring, consistency |
| Interview Questions | Gemma 2 9B | Fast response, natural conversation |
| Answer Evaluation | Gemma 2 9B | Conversational evaluation |
| Interview Summary | Gemma 2 9B | Natural language generation |
| Screening Report | Gemma 2 9B | Comprehensive analysis |
| Speech-to-Text | Deepgram | Low latency, high accuracy |
| Text-to-Speech | Cartesia | Natural voice quality |

---

## üåç Language Changes

| Component | Before | After |
|-----------|--------|-------|
| Interview Prompts | Thai (‡πÑ‡∏ó‡∏¢) | English |
| STT Language | `th` / `th-TH` | `en-US` |
| TTS Voice | `th-TH-Standard-A` | Cartesia English (Professional Female) |
| System Instructions | Thai | English |

---

## ‚öôÔ∏è Environment Variables

### New Variables Required:
```bash
# Ollama URLs (backend)
RESUME_AI_URL=http://ollama-deepseek:11434
INTERVIEW_AI_URL=http://ollama-gemma:11434

# Deepgram API Key (backend & agent)
DEEPGRAM_API_KEY=<your-key>
```

### Deprecated Variables:
```bash
# No longer needed
GEMINI_API_KEY=<removed>
GOOGLE_API_KEY=<removed>
```

---

## üê≥ Docker Services

### Updated docker-compose.yml:
```yaml
ollama-deepseek:
  image: ollama/ollama
  ports: ["11435:11434"]
  model: deepseek-r1:7b
  
ollama-gemma:
  image: ollama/ollama
  ports: ["11436:11434"]
  model: gemma2:9b-instruct-q8_0
```

---

## üß™ Testing Required

### Backend API Tests:
- [ ] `POST /api/ai/resume/parse` - Resume parsing (Word docs)
- [ ] `POST /api/ai/resume/screen` - Resume screening
- [ ] `POST /api/ai/screening/start` - Start screening conversation
- [ ] `POST /api/ai/screening/chat` - Chat during screening
- [ ] `POST /api/ai/screening/finalize` - Generate screening report
- [ ] `POST /api/ai/interview/score` - Score interview responses
- [ ] `POST /api/ai/interview/summary` - Generate interview summary

### LiveKit Agent Tests:
- [ ] Voice Interview (English) - Start session
- [ ] STT Accuracy (Deepgram English)
- [ ] TTS Quality (Cartesia English)
- [ ] Gemma 2 Conversation Flow
- [ ] Transcript Saving
- [ ] Session Timeout Handling

---

## ‚ö†Ô∏è Breaking Changes

### 1. Video Analysis
- **Status:** ‚ùå Not Supported
- **Reason:** Ollama models don't support video input
- **Workaround:** Use frame extraction + image analysis or external service

### 2. PDF/Image Resume Parsing
- **Status:** ‚ö†Ô∏è Requires Preprocessing
- **Reason:** DeepSeek can't directly process images
- **Workaround:** Use OCR service (Tesseract, Google Vision) to extract text first
- **Current:** Only Word (.doc, .docx) documents fully supported

### 3. Language Change
- **Status:** ‚ö†Ô∏è Breaking for Thai users
- **Impact:** All interviews now in English
- **Workaround:** Can revert prompts to Thai, but may need different TTS/STT

---

## üìà Performance Expectations

| Model | Response Time | GPU Memory | Cost |
|-------|---------------|------------|------|
| DeepSeek-R1 7B | 2-5s | ~8GB VRAM | $0 (local) |
| Gemma 2 9B | 1-3s | ~12GB VRAM | $0 (local) |
| Deepgram STT | ~100ms | 0 (cloud) | ~$0.0043/min |
| Cartesia TTS | ~200ms | 0 (cloud) | Pay-as-you-go |

**Total Local GPU Required:** ~20GB VRAM recommended (for simultaneous use)

---

## üöÄ Deployment Checklist

- [ ] Pull Ollama models (`./setup-ollama-models.ps1` or `.sh`)
- [ ] Update `.env` files (backend & agent)
- [ ] Install agent dependencies (`pip install -r agent/requirements.txt`)
- [ ] Rebuild Docker containers (`docker-compose build`)
- [ ] Start services (`docker-compose up -d`)
- [ ] Verify Ollama health (`curl localhost:11435/api/tags`)
- [ ] Test resume parsing
- [ ] Test live interview
- [ ] Monitor GPU usage

---

## üéì Key Learnings

1. **DeepSeek excels at structured extraction** - Perfect for resume parsing
2. **Gemma is fast and conversational** - Ideal for real-time interviews
3. **Deepgram is reliable** - Low latency, high accuracy for STT
4. **Ollama is production-ready** - Stable API, good Docker support
5. **Local + Cloud hybrid works** - Best of both worlds

---

## üìû Support

For issues related to:
- **Ollama:** Check container logs (`docker logs ollama-deepseek`)
- **Deepgram:** Verify API key and quota
- **Cartesia:** Check API credentials
- **Agent:** Check Python logs (`docker logs agent`)

---

## üéØ Next Steps

1. **Test all endpoints** with real data
2. **Monitor performance** under load
3. **Fine-tune prompts** for better responses
4. **Add OCR integration** for PDF/Image resume support
5. **Consider model quantization** if GPU memory is limited

---

**Migration Status:** ‚úÖ **Complete**  
**Production Ready:** ‚ö†Ô∏è **Pending Tests**

---

*For detailed architecture information, see `AI_ARCHITECTURE.md`*
